

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="SpriCoder">
  <meta name="keywords" content="">
  
    <meta name="description" content="2021-数据集成-Lec4-Python数据爬取技术与实战">
<meta property="og:type" content="article">
<meta property="og:title" content="2021-数据集成-Lec4-Python数据爬取技术与实战">
<meta property="og:url" content="https://spricoder.github.io/2021/05/01/2021-Data-Integration/2021-Data-Integration-Lec4-Python%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="SpriCoder的博客">
<meta property="og:description" content="2021-数据集成-Lec4-Python数据爬取技术与实战">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/1.png">
<meta property="og:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/2.png">
<meta property="og:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/3.png">
<meta property="og:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/4.png">
<meta property="og:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/5.png">
<meta property="article:published_time" content="2021-05-01T11:04:00.000Z">
<meta property="article:modified_time" content="2022-03-07T10:45:15.387Z">
<meta property="article:author" content="SpriCoder">
<meta property="article:tag" content="课程笔记">
<meta property="article:tag" content="数据集成">
<meta property="article:tag" content="数据抓取">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/1.png">
  
  
  <title>2021-数据集成-Lec4-Python数据爬取技术与实战 - SpriCoder的博客</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://cdn.staticfile.org/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"spricoder.github.io","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"DYxfU2PHurs2yXd95Sq85bU2-gzGzoHsz","app_key":"YWKSJ5KaDC4GQh2F8JraQPBr","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>SpriCoder的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/website.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          <span id="subtitle" title="2021-数据集成-Lec4-Python数据爬取技术与实战">
            
          </span>
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-05-01 19:04" pubdate>
          2021年5月1日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          71 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">2021-数据集成-Lec4-Python数据爬取技术与实战</h1>
            
            <div class="markdown-body">
              
              <h2 id="lec4-python数据爬取技术与实战"><a class="markdownIt-Anchor" href="#lec4-python数据爬取技术与实战"></a> Lec4-Python数据爬取技术与实战</h2>
<h1 id="1-字符串解析"><a class="markdownIt-Anchor" href="#1-字符串解析"></a> 1. 字符串解析</h1>
<ol>
<li>xls是二进制文件</li>
</ol>
<h2 id="11-常用函数"><a class="markdownIt-Anchor" href="#11-常用函数"></a> 1.1. 常用函数</h2>
<p>Python提供了基本字符串方法，可以对字符串进行简单处理。方法包括split()、replace()、strip()等。</p>
<h2 id="12-正则表达式"><a class="markdownIt-Anchor" href="#12-正则表达式"></a> 1.2. 正则表达式</h2>
<p>复杂的字符串处理可以使用正则表达式，下表展示了常用的正则表达式。</p>
<p><img src="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/1.png" srcset="/img/loading.gif" lazyload alt="" /></p>
<ol>
<li>正则表达式详细教程详见https://www.w3cschool.cn/zhengzebiaodashi/。</li>
<li>Python的re模块提供了大量的方法，实现了正则表达式的各类操作。详细的使用说明见https://docs.python.org/3/library/re.html。</li>
<li>以下实例给出正则表达式的一些简单使用方法。</li>
</ol>
<p><img src="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/2.png" srcset="/img/loading.gif" lazyload alt="" /></p>
<h2 id="13-字符串解析beautifulsoup"><a class="markdownIt-Anchor" href="#13-字符串解析beautifulsoup"></a> 1.3. 字符串解析BeautifulSoup</h2>
<ol>
<li>BeautifulSoup 是一个HTML/XML的解析器，主要功能是解析和提取 HTML/XML 数据。</li>
<li>BeautifulSoup4将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种:
<ol>
<li>Tag:标签，有name和attrs两个重要的属性</li>
<li>NavigableString:标签内部的文字</li>
<li>BeautifulSoup:表示的是一个文档的内容，可以将其当成一个特殊的Tag。</li>
<li>Comment:是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号。</li>
</ol>
</li>
<li>更多信息详见https://www.crummy.com/software/BeautifulSoup/bs4/doc/。</li>
<li>示例</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> re<br>file = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./aa.html&#x27;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>)<br>html = file.read()<br>bs = BeautifulSoup(html, <span class="hljs-string">&quot;html.parser&quot;</span>)<br><span class="hljs-comment">#查询id=head的Tag</span><br>t_list = bs.find_all(<span class="hljs-built_in">id</span>=<span class="hljs-string">&quot;head&quot;</span>)<br><span class="hljs-built_in">print</span>(t_list)<br><span class="hljs-comment">#查询href属性包含ss1.bdstatic.com的Tag</span><br>t_list = bs.find_all(href=re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">&quot;http://news.baidu.com&quot;</span>))<br><span class="hljs-built_in">print</span>(t_list)<br><span class="hljs-comment">#查询所有包含class的Tag(注意: class在Python中 属于关键字，所以加_以示区别)</span><br>t_list= bs.find_all(class_ =<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> t_list:<br>  <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure>
<ol start="5">
<li>json结构:数据处理中经常会遇到json格式的文档。Python提供了json模块用于json格式内容的处理。
<ol>
<li>json.dumps: 将Python对象编码成JSON字符串</li>
<li>json.loads: 将已编码的JSON字符串解码为Python对象</li>
</ol>
</li>
</ol>
<h1 id="2-单机数据爬取"><a class="markdownIt-Anchor" href="#2-单机数据爬取"></a> 2. 单机数据爬取</h1>
<ol>
<li>Spynner：Sypnner是基于pyqt的一种库，封装了pyqt强大的webkit，具有执行javascript的能力，使用Spynner可以完全模拟一个浏览器的功能和行为。在抓取的时候可以动态显示整个抓取进展。使用Spynner可以对javascript实现的动态内容进行抓取。详见https://pypi.org/project/spynner/。</li>
<li>requests：request是Python的http库，可以完成绝大部分与http应用相关的工作。与Spynner不同，requests是一种非界面化的库，它提供了丰富的且易于调用的多种方法实现对http相关方式的模拟。</li>
</ol>
<h2 id="21-spynner"><a class="markdownIt-Anchor" href="#21-spynner"></a> 2.1. Spynner</h2>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> spynner<br><span class="hljs-keyword">import</span> pyguery<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br>browser = spynner.Browser()<br>browser.create_webview()<br>browserset html_parser(pyquery.PyQuery)<br>browser.load(<span class="hljs-string">&quot;http://list.jd.com/list.html?cat=670,671 ,672&quot;</span>, load_timeout=<span class="hljs-number">20</span>)<br><span class="hljs-keyword">try</span>:<br>  browser.wait load(<span class="hljs-number">10</span>)<br><span class="hljs-keyword">except</span>:<br>  <span class="hljs-keyword">pass</span><br>string = browser.html<br>browser.close()<br>soup = BeautifulSoup.BeautifulSoup(string)<br>time.sleep(<span class="hljs-number">2</span>)<br>tags1 = soup.findAll(<span class="hljs-string">&#x27;div&#x27;</span>, &#123;<span class="hljs-string">&#x27;class&#x27;</span>: <span class="hljs-string">&#x27;sl-wrap&#x27;</span>&#125;)<br><span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> tags1:<br>  <span class="hljs-built_in">print</span>(tag)<br></code></pre></td></tr></table></figure>
<ol>
<li>爬取京东中&quot;电脑&quot;页面的信息，基本的流程是创建一个browser，打开指定url,等待加载完成后，读取browser中 的html进行解析，然后获取指定div节点列表,再通过一个for循环来遍历所有笔记本的信息并打印出来。</li>
</ol>
<h2 id="22-requests"><a class="markdownIt-Anchor" href="#22-requests"></a> 2.2. requests</h2>
<ol>
<li>我们主要围绕两个基本方法get和post的相关内容进行介绍。</li>
</ol>
<h3 id="221-get方法"><a class="markdownIt-Anchor" href="#221-get方法"></a> 2.2.1. get方法</h3>
<ol>
<li>下图展示了一个简单的get方法的例子。get的返回值resp是一个Response类的对象，对象的text属性包含了相应的HTML文本。response的属性还包括url、status_code、encoding等，方法有json()等，可以使用help(resp)查看response的各种属性和方法。</li>
</ol>
<p><img src="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/3.png" srcset="/img/loading.gif" lazyload alt="" /></p>
<h3 id="222-post方法"><a class="markdownIt-Anchor" href="#222-post方法"></a> 2.2.2. post方法</h3>
<ol>
<li>post在提交时需要提供类似表单的数据信息。</li>
</ol>
<p><img src="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/4.png" srcset="/img/loading.gif" lazyload alt="" /></p>
<h3 id="223-header和cookie"><a class="markdownIt-Anchor" href="#223-header和cookie"></a> 2.2.3. header和cookie</h3>
<ol>
<li>在抓取时可能对方会判断是否发送请求的一方是浏览器，如果是浏览器才进行响应，这样就需要将我们的request在请求时伪装成一个浏览器，通常的做法是设置headers。在实际抓取环境中，可以使用浏览器自带的开发控制台获得实际的headers。有时也需要设置cookie，获得方法与获得headers方法类似。</li>
</ol>
<p><img src="https://spricoder.oss-cn-shanghai.aliyuncs.com/2021-Data-Integration/img/spider/5.png" srcset="/img/loading.gif" lazyload alt="" /></p>
<h1 id="3-selenium"><a class="markdownIt-Anchor" href="#3-selenium"></a> 3. Selenium</h1>
<ol>
<li>Selenium主要用于Web开发领域的自动化测试，其提供的接口和方法也可用于数据抓取领域，基于grid技术可以方便地搭建分布式抓取环境。相比Spynner，Selenium的功能更为完备，文档资料也更加丰富。</li>
<li>利用Selenium可以实现对多种浏览器的调用，如Firefox、Chrome、IE、Opera等，基本的使用流程是相似的。</li>
<li>以FireFox为例来说明使用Selenium进行网页抓取的流程。抓取的目标为电子工业出版社网站，抓取首页http://www.phei.com.cn/，代码为</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment">#利用webdriver可以初始化各种浏览器</span><br><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-comment">#为了在后面调用sleep函数，在页面加载后有一定的时间间隔用于观察</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-comment">#初始化一个Firefox浏览器用于抓取的实施</span><br>firefox = webdriver.Firefox()<br><span class="hljs-comment">#抓取的目标网页地址</span><br>url = <span class="hljs-string">&#x27;http://www.phei.com.cn/&quot;</span><br><span class="hljs-string">#调用get方法抓取</span><br><span class="hljs-string">firefox.get(url)</span><br><span class="hljs-string">#有10s等待时间用于观察</span><br><span class="hljs-string">time.sleep(10)</span><br><span class="hljs-string">#将加载的页面保存在本地，存储的是页面加载后的HTML文本.</span><br><span class="hljs-string">with open(a.html&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>f.write(firefox.page_ source)<br><span class="hljs-comment">#抓取完毕后，调用quit()方 法退出浏览器</span><br>firefox.quit()<br></code></pre></td></tr></table></figure>
<h2 id="31-selenium的profile配置"><a class="markdownIt-Anchor" href="#31-selenium的profile配置"></a> 3.1. Selenium的Profile配置</h2>
<ol>
<li>Selenium在浏览器初始化时可以对浏览器的相关参数进行设置：
<ol>
<li>控制CSS。因为在抓取时只关心页面重要信息的获取，因此CSS样式表文件的加载和对页面的渲染是没有必要的，这在一定程度上可以减少抓取时间。</li>
<li>控制Javascript文件的加载和执行。如果我们关注的信息内容不是利用Javascript动态加载得到的，而且关注的信息在展示后还有大量的无关信息加载时，可以关闭Javascript的加载和执行功能。</li>
<li>控制图片的加载，极大的提高抓取效率。</li>
</ol>
</li>
</ol>
<h2 id="32-profile的配置示例"><a class="markdownIt-Anchor" href="#32-profile的配置示例"></a> 3.2. Profile的配置示例</h2>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-keyword">import</span> time<br>firefox_profile = webdriver.FirefoxProfile() <span class="hljs-comment">#初始化一个Firefox实例firefox_ profile</span><br>firefox_profile.set_preference( <span class="hljs-string">&quot;permissions.default.stylesheet&quot;</span>, <span class="hljs-number">2</span>) <span class="hljs-comment">#禁用样式表文件</span><br>firefox_profile.set_preference( <span class="hljs-string">&quot;permissions.default.image&quot;</span>, <span class="hljs-number">2</span>) <span class="hljs-comment">#不下载和加载图片</span><br>firefox_profile.set_preference( <span class="hljs-string">&quot;javascript.enabled&quot;</span> , <span class="hljs-literal">False</span>) <span class="hljs-comment">#禁止Javascript的执行</span><br>firefox_profile.update_preferences() <span class="hljs-comment">#更新设置</span><br><span class="hljs-comment">#利用firefox_ profile 初始化浏览器，此时浏览器初始化Firefox具有参数所设定的行为</span><br>firefox = webdriver. Firefox(firefox_profile)<br>url = <span class="hljs-string">&#x27;http://www.phei.com.cn/</span><br><span class="hljs-string">t_start = time.time()</span><br><span class="hljs-string">firefox.get(ur)</span><br><span class="hljs-string">print(&#x27;</span>loading time <span class="hljs-keyword">is</span>: <span class="hljs-string">&#x27;, time.time()-t_start)</span><br><span class="hljs-string">time.sleep(10)</span><br><span class="hljs-string">firefox.quit()</span><br></code></pre></td></tr></table></figure>
<h2 id="33-动态内容抓取"><a class="markdownIt-Anchor" href="#33-动态内容抓取"></a> 3.3. 动态内容抓取</h2>
<ol>
<li>雪球网的帖子是动态加载的，我们以此为例使用Selenium爬取帖子</li>
<li>使用request无法抓取到全面的数据（如下图所示，无法获取全部的数据）。因为网页的内容是随着滚动逐步加载的。根据这一特点，可以使用Selenium来完成抓取工作。</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> requests<br>url = <span class="hljs-string">&#x27;https://xueqiu.com&#x27;</span><br>headers = &#123;<br>  <span class="hljs-string">&quot;User-Agent&quot;</span>:<span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, likeGecko)&quot;</span><br>  <span class="hljs-string">&quot;Chrome/74.0.3729. 108 Safari/537 .36&quot;</span>,&#125;<br>cookie = &#123;<span class="hljs-string">&#x27;ID&#x27;</span>:<span class="hljs-string">&quot;1 586965804&#x27;&#125;</span><br><span class="hljs-string">resp = requests.get(url=url, headers=headers, cookie=cookie)</span><br><span class="hljs-string">S = resp.text</span><br><span class="hljs-string">print(len(s))</span><br><span class="hljs-string">with open( &#x27;xueqiu.html&#x27;, w, encoding=&#x27;utf8&#x27;) as f:</span><br><span class="hljs-string">  f.write(s)</span><br></code></pre></td></tr></table></figure>
<ol>
<li>下面的实例利用Selenium执行Javascript脚本的能力，利用脚本来控制浏览器的滚动条，并通过滚动条的滚动动态加载内容。</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json <span class="hljs-comment">#用于格式化存入文件</span><br><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver <span class="hljs-comment">#自动化测试工具</span><br><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree <span class="hljs-comment">#使用xpath解析</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">1.爬取雪球网，获取url</span><br><span class="hljs-string">2.使用自动化测试工具打开雪球网</span><br><span class="hljs-string">3.需要使用自动化测试工具循环下拉滚动条三次，获取到动态加载的数据</span><br><span class="hljs-string">4.然后使用自动化测试工具点击加载更多的button按钮，来获取到更多的数据</span><br><span class="hljs-string">5.对获取到的数据进行解析,拿取需要的数据</span><br><span class="hljs-string">6.将数据循环以词典添加到列表中</span><br><span class="hljs-string">7.将列表数据写入到文件中,并且需要将列表转换为json字符串</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>starttime=time.time()<span class="hljs-comment">#开始时间，用于测试爬虫的时长</span><br>url =<span class="hljs-string">&quot;https://xueqiu.com&quot;</span> <span class="hljs-comment">#雪球网的url,默认就为推荐数据</span><br><span class="hljs-comment">#实例化浏览器对象,以谷歌浏览器运行，</span><br>browser = webdriver.Chrome()<br>browser.get(urI) <span class="hljs-comment">#打开对应的url</span><br><span class="hljs-comment">#下拉滚动条三次,三次之后就需要点击加载更多的按钮，可自己下拉查看</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>browser.execute_script(<span class="hljs-string">&#x27;window.scrollTo(0, document.body.scrollHeight&#x27;</span>)<br>time.sleep(<span class="hljs-number">1</span> <span class="hljs-number">.5</span>)<br><span class="hljs-comment">#获取加载更多的按钮</span><br>button = browser.find_element_by_class_name(<span class="hljs-string">&quot;AnonymousHome_home_timeline_more_6RI&quot;</span>)<br><span class="hljs-keyword">try</span>:<br><span class="hljs-comment">#循环点击这个按钮，并且下拉获取到更多的数据,此处循环自行设置,可以不必循环太多次</span><br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    button.click() <span class="hljs-comment">#点击这个按钮</span><br>    <span class="hljs-comment">#点击按钮之后会展示更多的数据,然后继续下拉滚动条来获取加载更多按钮</span><br>    browser.execute_script(<span class="hljs-string">&#x27;window.scrollTo(0, document.body.scrollHeight)</span><br><span class="hljs-string">    time.sleep(2)</span><br><span class="hljs-string">except Exception as e:</span><br><span class="hljs-string">  print(&#x27;</span>出错了:<span class="hljs-string">&#x27;, e)</span><br><span class="hljs-string">else:</span><br><span class="hljs-string">  #如果没有出错,那么则获取到了全部(大量)的数据,下面要对数据进行解析,取出所需数据</span><br><span class="hljs-string">  #获取到的网页源码就是str类型，不需要再使用text获取htm|文本数据</span><br><span class="hljs-string">  tree = etree.HTML(browser.page_ source)</span><br><span class="hljs-string">  #获取到所有的a标签</span><br><span class="hljs-string">  a_list = tree.xpath(&#x27;</span>/div[@<span class="hljs-keyword">class</span>=<span class="hljs-string">&quot;AnonymousHome_home_timeline_item_3vU&quot;</span>]/h3/a<span class="hljs-string">&#x27; )</span><br><span class="hljs-string">  result_list= []</span><br><span class="hljs-string">  for a in a_list:</span><br><span class="hljs-string">    result_ dict = dict()</span><br><span class="hljs-string">    title = a.text #标签中的文字可直接使用text获取文本或者再次使用xpath匹配</span><br><span class="hljs-string">    #因为xpath匹配出来后的数据是放在列表中,所以要从列表中拿出来</span><br><span class="hljs-string">    href = url + a.xpath(&#x27;</span>./@hre<span class="hljs-string">f&#x27; )[0]</span><br><span class="hljs-string">    result_dict[&quot;title&quot;] = title #将数据添加到字典中</span><br><span class="hljs-string">    result_dict[&quot;ur&quot;]= href</span><br><span class="hljs-string">    result_listappend(result_dict) #将字典添加到列表中</span><br><span class="hljs-string">    #此处循环完毕后列表中有多个字典,可以将列表写入文件(数据库)中，以便查看数据</span><br><span class="hljs-string">  with open(&#x27;</span>xue_qiu.json<span class="hljs-string">&#x27; ，&#x27;</span>w<span class="hljs-string">&#x27; , encoding=‘utf-8’ ) as f: </span><br><span class="hljs-string">  #写入文件要将python格式转换为json字符串写入</span><br><span class="hljs-string">    f.write(json.dumps(result_list, ensure_asci=False, indent=2))</span><br><span class="hljs-string">  browser.quit() #退出浏览器</span><br><span class="hljs-string">print(&quot;总耗时:%d&quot; % (time.time() - start_time)) #打印爬取数据的总时长</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure>
<h1 id="4-tor"><a class="markdownIt-Anchor" href="#4-tor"></a> 4. Tor</h1>
<ol>
<li>Tor是一种开源的网络工具，使用Tor可以防止他人了解到我们的位置和访问习惯。</li>
<li>Tor可以将我们发出的请求在接入的网络中传送，然后通过在某个也接入到Tor网络系统中的机器将请求发送到目标站点，得到响应后，Tor再将响应传回我们的机器。这个过程比常规的访问方式要长，但有一个特点是可以控制Tor。Tor就像一个“IP泵”一样，源源不断的产生各种IP，为我们发送请求。</li>
<li>抓取时IP被封锁的问题
<ol>
<li>通常，网站会对访问设置一定的规则，对于抓取来说，主要面对的问题是对抓取频次的限制。当抓取过快时，如果超过这一限制，网站就会进行阻止和封锁。不同的网站有不同的封锁策略，主要表现为在一段时间内，用户无法访问，直至网站解除对此IP的封锁</li>
</ol>
</li>
<li>Tor实施抓取具有以下特点：
<ol>
<li>可以生成不同的可用IP地址对目标进行访问；</li>
<li>本机操作相对于各种免费代理更加可靠和稳定；</li>
<li>无需费用，Tor是一种免费的软件。</li>
</ol>
</li>
<li>下面的代码的主要工作是在Tor的协助下进行数据抓取。每一次抓取会使用不同的IP地址。</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> socks<br><span class="hljs-keyword">import</span> socket<br><span class="hljs-keyword">from</span> stem:control <span class="hljs-keyword">import</span> Controtler <span class="hljs-comment"># stem是控制Tor的库</span><br><span class="hljs-keyword">from</span> stem <span class="hljs-keyword">import</span> Signal<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> time<br>counter= <span class="hljs-number">0</span> <br>controller = Controller.from_port(port=<span class="hljs-number">9151</span>)<br>controller.authenticate()<br>socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS, <span class="hljs-string">&quot;127.0.0.1&quot;</span>, <span class="hljs-number">9150</span>)<br>socket.socket = socks.socksocket<br>url_ip = <span class="hljs-string">&#x27;http://jsonip.com/&#x27;</span><br>url_pub = <span class="hljs-string">&#x27;http://www.phei.com.cn/</span><br><span class="hljs-string">while counter &lt; 5:</span><br><span class="hljs-string">  try:</span><br><span class="hljs-string">    r = requests.get(url_ip)</span><br><span class="hljs-string">    ip_val = r.json()[&#x27;</span>ip<span class="hljs-string">&#x27;]</span><br><span class="hljs-string">    print(counter, &#x27;</span>当前ip:<span class="hljs-string">&#x27;, ip_ val)</span><br><span class="hljs-string">    time1 = time.time()</span><br><span class="hljs-string">    r2 = requests.get(url_ _pub)</span><br><span class="hljs-string">    print(counter, &#x27;</span>抓取时间:, time.time() - time1)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(ip_ _val + <span class="hljs-string">&#x27; _pub.html&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    f.write(r2.text)<br>    time2 = time.time()<br>    controller. signal(Signal.NEWNYM)<br>    time.sleep(controller.get_ newnym_ wait()<br>    <span class="hljs-built_in">print</span>(counter, <span class="hljs-string">&#x27;改变IP时间: &#x27;</span>, time.time() - time2)<br>    counter = counter + <span class="hljs-number">1</span><br>  <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>    <span class="hljs-built_in">print</span>(e)<br></code></pre></td></tr></table></figure>
<h1 id="5-爬取常见问题"><a class="markdownIt-Anchor" href="#5-爬取常见问题"></a> 5. 爬取常见问题</h1>
<ol>
<li>Flash：Flash与服务器间的通信有时会将请求加密，同时返回的信息也被加密。可以通过对Flash控件的分析找出加密和解密对应的模块，进而分析出密钥，在拥有密钥的情况下，整个过程就变得透明和简单。</li>
<li>桌面程序或App
<ol>
<li>使用Wireshark进行辅助分析监控整个系统通过网络和外界进行交互时的协议使用情况和协议的内容。</li>
<li>设置Wifi热点，使移动设备通过该热点连接网络，利用Wireshark对热点进行网络流量的分析，从而抓取App通过热点与服务器交互的请求和响应数据。</li>
</ol>
</li>
<li>图片的处理
<ol>
<li>目标网站可能出于信息保护的目的，将一些关键的信息，尤其是数字相关信息以图片的方式展示出来。我们可以将图片中的数字转化为文本数字。转化的方式可以使用PIL库来执行，或者寻找其他的库，如大多数机器学习库中包含的一些监督式学习算法，经适当修改后也可以用作数字的识别与处理。</li>
</ol>
</li>
<li>设置请求时间间隔
<ol>
<li>大规模集中访问对服务器的影响较大，爬虫可以短时间增大服务器负载。等待时间过长，不能满足短时间大规模抓取的要求，等待时间过短则很有可能被拒绝访问。</li>
<li>设置合理的请求时间间隔，既保证爬虫的抓取效率，又不对对方服务器造成较大影响</li>
</ol>
</li>
</ol>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/2021-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90/" class="category-chain-item">2021-数据集成</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">#课程笔记</a>
      
        <a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90/">#数据集成</a>
      
        <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96/">#数据抓取</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>2021-数据集成-Lec4-Python数据爬取技术与实战</div>
      <div>https://spricoder.github.io/2021/05/01/2021-Data-Integration/2021-Data-Integration-Lec4-Python%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>SpriCoder</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年5月1日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/05/01/2021-Data-Integration/2021-Data-Integration-Lec5-%E6%89%B9%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90/" title="2021-数据集成-Lec5-批数据集成">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">2021-数据集成-Lec5-批数据集成</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/05/01/2021-Data-Integration/2021-Data-Integration-Lec3-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E6%A1%86%E6%9E%B6/" title="2021-数据集成-Lec3-数据集成框架">
                        <span class="hidden-mobile">2021-数据集成-Lec3-数据集成框架</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'SpriCoder/spricoder-blog-comment');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <div> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
  </div>
  <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  <!-- <div class="beian">
  <span>
    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
      京ICP证123456号
    </a>
  </span>
  
    
      <span>
        <a
          href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
          rel="nofollow noopener"
          class="beian-police"
          target="_blank"
        >
          
            <span style="visibility: hidden; width: 0">|</span>
            <img src="/img/police_beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
          
          <span>京公网安备12345678号</span>
        </a>
      </span>
    
  
</div>
 -->
  
</footer>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.staticfile.org/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  
    <script  src="/js/img-lazyload.js" ></script>
  



  <script  src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var title = subtitle.title;
      
        typing(title);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  





  
<script>
  Fluid.utils.createScript('https://cdn.staticfile.org/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.staticfile.org/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
